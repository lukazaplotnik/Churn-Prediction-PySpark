# Churn Prediction with PySpark

### Project Motivation

#### Business Context
Sparkify is a fictitious music streaming service, created by Udacity to mimic the datasets generated by companies such as Spotify or Pandora. Millions of users play their favorite songs through such services on a daily basis, either through free tier that plays advertisements, or by using a premium subscription model which offers additional functionalities and is typically ad-free. Users can upgrade or downgrade their service any time, but also cancel it altogether, so it is very important to make sure the users like the service. Every time a user interacts with the service, whether playing songs, adding them to playlists, rating them with the thumbs down/up, adding a friend, logging in or out, changing settings, this generates data. All this user activity data contains key insights for helping the business understand whether the users are happy with the service.

In order to make sure the business stays on track with its (financial) goals, it is very important to identify the users that are likely to churn - users who are at risk of downgrading from premium to free tier, or cancelling the service altogether. If businesses can accurately identify these users in advance before they leave they can offer them discounts and other similar incentives and save millions in revenues. It is a well known fact that it is more expensive to acquire a new customer than it is to retain an existing one.

#### Project Overview
The aim of this project is to build and train a supervised machine learning model (specifically, a binary classifier) that would be able to accurately identify users who are likely to cancel the music streaming service (applies to both free and paid tier users), based on the information contained in the user activity logs recorded within a given observation window. The data used for training is the simulated Sparkify activity data provided by Udacity. The project is carried out by leveraging the Apache Spark distributed cluster-computing framework capabilities, through Python API for Spark, PySpark. The initial stages of model development are performed on a smaller subset of the dataset using Spark in local mode, whereas the entire Sparkify dataset is too big to be processed locally and therefore an Elastic MapReduce (EMR) cluster has been deployed on the AWS cloud to train the final instance of the model.

The project consists of three main steps:

TODO:


### File Descriptions
- sparkify_main.ipynb : Jupyter notebook with all the analyses, modelling steps, code, results, visualizations, plus all supporting discussions and comprehensive documentation
- sparkify_cluster.ipynb : slim-down version of the main Jupyter notebook adapted to train selected models on the AWS EMR cluster

The full Sparkify dataset (12GB) used in this project is hosted on Udacity's publicly available Amazon S3 bucket: s3n://udacity-dsnd/sparkify/sparkify_event_data.json

The smaller version used for data exploration (123MB) is available under: s3n://udacity-dsnd/sparkify/mini_sparkify_event_data.json


### Results
The results and conclusions are best presented in the accompanying [Medium article](https://medium.com/@lukazaplotnik/TODO).


### Acknowledgments
The data used in this project has been simulated by Udacity to mimic the data generated by actual music streaming companies. I have to give credit to Udacity for designing projects that are as close as possible to real world scenarios and for preparing the students for the challenges they will face on the job.

### Libraries
- PySpark version 2.4.3 was used in this project, mainly `pyspark.sql` module for working with structure data and `pyspark.ml` that provides a set of high-level APIs to create practical machine learning pipelines
- no additional libraries have been used beyond the Anaconda distribution of Python, and there should be no issues running the code using Python versions 3.x
